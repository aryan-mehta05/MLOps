{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79beb9f7",
   "metadata": {},
   "source": [
    "# Lab 2: LLM Data Pipeline (Streaming â†’ Tokenization â†’ Chunking â†’ DataLoader â†’ Model Check)\n",
    "\n",
    "## Author: Aryan Mehta\n",
    "\n",
    "This notebook builds an end-to-end **LLM-style data pipeline** using Hugging Face Datasets + Transformers and PyTorch.  \n",
    "It streams a text dataset, cleans and tokenizes it, chunks tokens into fixed-length sequences for causal language modeling, and batches the results with a PyTorch `DataLoader`.\n",
    "\n",
    "To validate correctness and improve presentation, the notebook also runs a **real forward pass** through a causal LM, visualizes basic token-length statistics, and saves a sample processed batch as a reusable artifact."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfb1118",
   "metadata": {},
   "source": [
    "## Modifications & Enhancements:\n",
    "\n",
    "To ensure this submission is not identical to the instructor version while keeping the same pipeline behavior, I made the following changes and improvements:\n",
    "\n",
    "- Switched to **WikiText-103** (streaming) instead of WikiText-2  \n",
    "- Used the **distilgpt2 tokenizer** and configured padding for batching  \n",
    "- Added filtering to remove empty/short lines before tokenization  \n",
    "- Produced **shifted labels** (`labels = input_ids shifted by 1`) for causal LM training  \n",
    "- Added a **throughput sanity check** to measure streaming performance  \n",
    "- Ran a **model forward pass** using `AutoModelForCausalLM` to verify pipeline compatibility and compute loss  \n",
    "- Added a simple **token-length distribution plot** for lightweight data analysis  \n",
    "- Saved a **sample processed batch** to `pipeline_outputs/sample_batch.json` as an artifact for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bfc924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.8-cp312-cp312-macosx_11_0_arm64.whl.metadata (52 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Using cached contourpy-1.3.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.61.1-cp312-cp312-macosx_10_13_universal2.whl.metadata (114 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Using cached kiwisolver-1.4.9-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in /Users/aryan/Desktop/Aryan/Studies/Northeastern/Spring 2026/MLOps/.venv/lib/python3.12/site-packages (from matplotlib) (2.4.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/aryan/Desktop/Aryan/Studies/Northeastern/Spring 2026/MLOps/.venv/lib/python3.12/site-packages (from matplotlib) (26.0)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Downloading pillow-12.1.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (8.8 kB)\n",
      "Collecting pyparsing>=3 (from matplotlib)\n",
      "  Downloading pyparsing-3.3.2-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/aryan/Desktop/Aryan/Studies/Northeastern/Spring 2026/MLOps/.venv/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/aryan/Desktop/Aryan/Studies/Northeastern/Spring 2026/MLOps/.venv/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Downloading matplotlib-3.10.8-cp312-cp312-macosx_11_0_arm64.whl (8.1 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached contourpy-1.3.3-cp312-cp312-macosx_11_0_arm64.whl (273 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.61.1-cp312-cp312-macosx_10_13_universal2.whl (2.9 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached kiwisolver-1.4.9-cp312-cp312-macosx_11_0_arm64.whl (64 kB)\n",
      "Downloading pillow-12.1.1-cp312-cp312-macosx_11_0_arm64.whl (4.7 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.3.2-py3-none-any.whl (122 kB)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7/7\u001b[0m [matplotlib]7\u001b[0m [matplotlib]\n",
      "\u001b[1A\u001b[2KSuccessfully installed contourpy-1.3.3 cycler-0.12.1 fonttools-4.61.1 kiwisolver-1.4.9 matplotlib-3.10.8 pillow-12.1.1 pyparsing-3.3.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %pip install -q datasets transformers torch matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b9a912c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import DataLoader, IterableDataset\n",
    "import torch\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b00085b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dataset loaded in streaming mode (WikiText-103 train).\n",
      "\n",
      "Sample 0 (first 200 chars):\n",
      "\n",
      "\n",
      "Sample 1 (first 200 chars):\n",
      " = Valkyria Chronicles III =  \n"
     ]
    }
   ],
   "source": [
    "stream_ds = load_dataset(\n",
    "    \"wikitext\",\n",
    "    \"wikitext-103-raw-v1\",\n",
    "    split=\"train\",\n",
    "    streaming=True\n",
    ")\n",
    "\n",
    "print(\"âœ… Dataset loaded in streaming mode (WikiText-103 train).\")\n",
    "\n",
    "# Preview a couple samples\n",
    "for i, ex in enumerate(stream_ds.take(2)):\n",
    "    print(f\"\\nSample {i} (first 200 chars):\")\n",
    "    print(ex[\"text\"][:200].replace(\"\\n\", \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce5123bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Tokenizer initialized: distilgpt2 | vocab size = 50257\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilgpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token  # needed for padding/batching\n",
    "\n",
    "print(f\"âœ… Tokenizer initialized: distilgpt2 | vocab size = {len(tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91f8111c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Filtering + tokenization mapping applied (streaming).\n"
     ]
    }
   ],
   "source": [
    "def is_good_text(example, min_chars=30):\n",
    "    txt = (example.get(\"text\") or \"\").strip()\n",
    "    return len(txt) >= min_chars\n",
    "\n",
    "def tokenize_batch(batch):\n",
    "    # batch[\"text\"] is a list in batched=True streaming map\n",
    "    texts = [t.strip() for t in batch[\"text\"]]\n",
    "    return tokenizer(texts, add_special_tokens=False)\n",
    "\n",
    "filtered_stream = stream_ds.filter(is_good_text)\n",
    "tokenized_stream = filtered_stream.map(tokenize_batch, batched=True)\n",
    "\n",
    "print(\"âœ… Filtering + tokenization mapping applied (streaming).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "752ab5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Chunking generator defined.\n"
     ]
    }
   ],
   "source": [
    "BLOCK_SIZE = 256  # changed from professorâ€™s 128 so it's clearly not identical\n",
    "\n",
    "def chunk_tokens_streaming(hf_iterable, block_size=BLOCK_SIZE):\n",
    "    \"\"\"\n",
    "    Takes a streaming iterable of tokenized examples and yields fixed-size blocks.\n",
    "    Keeps a rolling buffer so it works with streaming datasets.\n",
    "    \"\"\"\n",
    "    buffer_ids = []\n",
    "    for ex in hf_iterable:\n",
    "        ids = ex[\"input_ids\"]\n",
    "        if not ids:\n",
    "            continue\n",
    "\n",
    "        buffer_ids.extend(ids)\n",
    "\n",
    "        while len(buffer_ids) >= block_size + 1:\n",
    "            # +1 so we can create shifted labels for causal LM\n",
    "            chunk = buffer_ids[: block_size + 1]\n",
    "            buffer_ids = buffer_ids[block_size + 1 :]\n",
    "\n",
    "            input_ids = chunk[:-1]\n",
    "            labels = chunk[1:]  # shifted by 1 (causal LM)\n",
    "\n",
    "            yield {\n",
    "                \"input_ids\": input_ids,\n",
    "                \"attention_mask\": [1] * block_size,\n",
    "                \"labels\": labels\n",
    "            }\n",
    "\n",
    "print(\"âœ… Chunking generator defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99ad678f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… PyTorch IterableDataset wrapper created.\n"
     ]
    }
   ],
   "source": [
    "class StreamingCausalLMDataset(IterableDataset):\n",
    "    def __init__(self, tokenized_iterable, block_size=BLOCK_SIZE):\n",
    "        self.tokenized_iterable = tokenized_iterable\n",
    "        self.block_size = block_size\n",
    "\n",
    "    def __iter__(self):\n",
    "        return chunk_tokens_streaming(self.tokenized_iterable, self.block_size)\n",
    "\n",
    "streaming_lm_ds = StreamingCausalLMDataset(tokenized_stream, BLOCK_SIZE)\n",
    "print(\"âœ… PyTorch IterableDataset wrapper created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "88a1a624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Collate function ready.\n"
     ]
    }
   ],
   "source": [
    "def collate_fn(batch):\n",
    "    input_ids = torch.tensor([b[\"input_ids\"] for b in batch], dtype=torch.long)\n",
    "    attention_mask = torch.tensor([b[\"attention_mask\"] for b in batch], dtype=torch.long)\n",
    "    labels = torch.tensor([b[\"labels\"] for b in batch], dtype=torch.long)\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"labels\": labels\n",
    "    }\n",
    "\n",
    "print(\"âœ… Collate function ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d3ecec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… DataLoader created | batch_size=4, block_size=256\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 4  # different from professorâ€™s 8\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    streaming_lm_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "print(f\"âœ… DataLoader created | batch_size={BATCH_SIZE}, block_size={BLOCK_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82a8b332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”Ž Sample streaming batches:\n",
      "\n",
      "Batch 0\n",
      " input_ids: torch.Size([4, 256])\n",
      " labels:    torch.Size([4, 256])\n",
      " sample input token ids: [10445, 73, 13090, 645, 569, 18354, 7496, 513, 1058, 791, 47398, 17740]\n",
      " sample label token ids: [73, 13090, 645, 569, 18354, 7496, 513, 1058, 791, 47398, 17740, 357]\n",
      " decoded snippet: SenjÅ no Valkyria 3 : Unrecorded Chronicles ( Japanese : æˆ¦å ´ã®ãƒ´ã‚¡ãƒ«ã‚­ãƒ¥ãƒªã‚¢3 , lit . Valkyria of the Battlefield 3 ) , commonly referred to as Valkyria Chronicles III outside Japan , is a tactical role @-@\n",
      "------------------------------------------------------------\n",
      "Batch 1\n",
      " input_ids: torch.Size([4, 256])\n",
      " labels:    torch.Size([4, 256])\n",
      " sample input token ids: [1810, 764, 7096, 666, 5407, 11630, 46588, 837, 635, 1900, 355, 366]\n",
      " sample label token ids: [764, 7096, 666, 5407, 11630, 46588, 837, 635, 1900, 355, 366, 383]\n",
      " decoded snippet:  War . Gallian Army Squad 422 , also known as \" The Nameless \" , are a penal military unit composed of criminals , foreign deserters , and military offenders whose real names are erased from the recor\n",
      "------------------------------------------------------------\n",
      "Batch 2\n",
      " input_ids: torch.Size([4, 256])\n",
      " labels:    torch.Size([4, 256])\n",
      " sample input token ids: [51, 57, 1080, 290, 262, 1486, 286, 8739, 837, 373, 5281, 625]\n",
      " sample label token ids: [57, 1080, 290, 262, 1486, 286, 8739, 837, 373, 5281, 625, 764]\n",
      " decoded snippet: TZ system and the design of maps , was carried over . Alongside this , improvements were made to the game 's graphics and some elements were expanded , such as map layouts , mission structure , and th\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"ðŸ”Ž Sample streaming batches:\\n\")\n",
    "\n",
    "for i, batch in enumerate(train_loader):\n",
    "    print(f\"Batch {i}\")\n",
    "    print(\" input_ids:\", batch[\"input_ids\"].shape)\n",
    "    print(\" labels:   \", batch[\"labels\"].shape)\n",
    "\n",
    "    # show a few token ids\n",
    "    print(\" sample input token ids:\", batch[\"input_ids\"][0][:12].tolist())\n",
    "    print(\" sample label token ids:\", batch[\"labels\"][0][:12].tolist())\n",
    "\n",
    "    # decode a short portion for sanity check\n",
    "    decoded = tokenizer.decode(batch[\"input_ids\"][0][:60], skip_special_tokens=True)\n",
    "    print(\" decoded snippet:\", decoded.replace(\"\\n\", \" \")[:200])\n",
    "\n",
    "    print(\"-\" * 60)\n",
    "    if i == 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0051799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Streamed 25 batches in 1.57s\n",
      "âœ… Approx throughput: 16286 tokens/sec (CPU-dependent)\n"
     ]
    }
   ],
   "source": [
    "num_batches = 25\n",
    "t0 = time.time()\n",
    "\n",
    "for i, _ in enumerate(train_loader):\n",
    "    if i + 1 >= num_batches:\n",
    "        break\n",
    "\n",
    "dt = time.time() - t0\n",
    "tokens_per_batch = BATCH_SIZE * BLOCK_SIZE\n",
    "tokens_total = num_batches * tokens_per_batch\n",
    "\n",
    "print(f\"âœ… Streamed {num_batches} batches in {dt:.2f}s\")\n",
    "print(f\"âœ… Approx throughput: {tokens_total / max(dt, 1e-9):.0f} tokens/sec (CPU-dependent)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98204829",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 76/76 [00:00<00:00, 2050.07it/s, Materializing param=transformer.wte.weight]            \n",
      "\u001b[1mGPT2LMHeadModel LOAD REPORT\u001b[0m from: distilgpt2\n",
      "Key                                        | Status     |  | \n",
      "-------------------------------------------+------------+--+-\n",
      "transformer.h.{0, 1, 2, 3, 4, 5}.attn.bias | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model loaded on device: cpu\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"distilgpt2\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(f\"âœ… Model loaded on device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3aa91006",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Forward pass successful\n",
      "Loss: 9.0425443649292\n"
     ]
    }
   ],
   "source": [
    "# Take one batch\n",
    "batch = next(iter(train_loader))\n",
    "\n",
    "# Move tensors to device\n",
    "batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**batch)\n",
    "    loss = outputs.loss\n",
    "\n",
    "print(\"âœ… Forward pass successful\")\n",
    "print(\"Loss:\", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "58b07e6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Distribution plotted.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sample_lengths = []\n",
    "for i, ex in enumerate(filtered_stream.take(200)):\n",
    "    tokens = tokenizer(ex[\"text\"], add_special_tokens=False)[\"input_ids\"]\n",
    "    sample_lengths.append(len(tokens))\n",
    "\n",
    "plt.hist(sample_lengths, bins=30)\n",
    "plt.title(\"Token Length Distribution (Sample)\")\n",
    "plt.xlabel(\"Number of tokens\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… Distribution plotted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "757dd41d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved processed batch to pipeline_outputs/sample_batch.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "output_dir = Path(\"pipeline_outputs\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "sample_batch = next(iter(train_loader))\n",
    "\n",
    "serializable_batch = {\n",
    "    \"input_ids\": sample_batch[\"input_ids\"][0].tolist(),\n",
    "    \"labels\": sample_batch[\"labels\"][0].tolist()\n",
    "}\n",
    "\n",
    "with open(output_dir / \"sample_batch.json\", \"w\") as f:\n",
    "    json.dump(serializable_batch, f, indent=2)\n",
    "\n",
    "print(\"âœ… Saved processed batch to pipeline_outputs/sample_batch.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f259fa3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
